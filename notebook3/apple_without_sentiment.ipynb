{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fff1b253",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\INDIA\\AppData\\Local\\Temp\\ipykernel_86424\\662369626.py:25: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  df = yf.download(ticker, start=start, end=end)\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestRegressor,\n",
    "    GradientBoostingRegressor,\n",
    "    VotingRegressor,\n",
    "    StackingRegressor\n",
    ")\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "import yfinance as yf\n",
    "from datetime import datetime\n",
    "\n",
    "# -------------------------------\n",
    "# 1. Download Stock Data (AAPL)\n",
    "# -------------------------------\n",
    "ticker = \"AAPL\"\n",
    "start = \"2022-01-01\"\n",
    "end = datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "df = yf.download(ticker, start=start, end=end)\n",
    "\n",
    "# Keep OHLC\n",
    "df = df[[\"Open\", \"High\", \"Low\", \"Close\"]].reset_index()\n",
    "\n",
    "# Create target: Next day's Close\n",
    "df[\"Next_Close\"] = df[\"Close\"].shift(-1)\n",
    "df = df.dropna().reset_index(drop=True)\n",
    "\n",
    "# -------------------------------\n",
    "# 2. Features & Preprocessor\n",
    "# -------------------------------\n",
    "features = [\"Open\", \"High\", \"Low\", \"Close\"]\n",
    "X = df[features]\n",
    "y = df[\"Next_Close\"]\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[(\"num\", StandardScaler(), features)],\n",
    "    remainder=\"passthrough\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# 3. Candidate Models\n",
    "# -------------------------------\n",
    "lr = LinearRegression()\n",
    "rf = RandomForestRegressor(n_estimators=200, max_depth=10, random_state=42)\n",
    "gb = GradientBoostingRegressor(n_estimators=200, learning_rate=0.05, max_depth=5, random_state=42)\n",
    "\n",
    "voting_reg = VotingRegressor(estimators=[(\"lr\", lr), (\"rf\", rf), (\"gb\", gb)])\n",
    "weighted_voting_reg = VotingRegressor(\n",
    "    estimators=[(\"lr\", lr), (\"rf\", rf), (\"gb\", gb)],\n",
    "    weights=[1, 2, 2]\n",
    ")\n",
    "stacking_reg = StackingRegressor(\n",
    "    estimators=[(\"lr\", lr), (\"rf\", rf), (\"gb\", gb)],\n",
    "    final_estimator=Ridge(alpha=1.0)\n",
    ")\n",
    "\n",
    "models = {\n",
    "    \"Linear Regression\": lr,\n",
    "    \"Random Forest\": rf,\n",
    "    \"Gradient Boosting\": gb,\n",
    "    \"Voting\": voting_reg,\n",
    "    \"Weighted Voting\": weighted_voting_reg,\n",
    "    \"Stacking\": stacking_reg\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f443cb1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Selected columns, ['Open', 'High', 'Low', 'Close'], are not unique in dataframe",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m X_train, X_test \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39miloc[train_idx], X\u001b[38;5;241m.\u001b[39miloc[test_idx]\n\u001b[0;32m     13\u001b[0m y_train, y_test \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39miloc[train_idx], y\u001b[38;5;241m.\u001b[39miloc[test_idx]\n\u001b[1;32m---> 15\u001b[0m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m pipeline\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m     18\u001b[0m mae_scores\u001b[38;5;241m.\u001b[39mappend(mean_absolute_error(y_test, y_pred))\n",
      "File \u001b[1;32md:\\new_stock_prediction\\venv\\lib\\site-packages\\sklearn\\base.py:1365\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1358\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1360\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1361\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1362\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1363\u001b[0m     )\n\u001b[0;32m   1364\u001b[0m ):\n\u001b[1;32m-> 1365\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\new_stock_prediction\\venv\\lib\\site-packages\\sklearn\\pipeline.py:655\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    648\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    649\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe `transform_input` parameter can only be set if metadata \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    650\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrouting is enabled. You can enable metadata routing using \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    651\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`sklearn.set_config(enable_metadata_routing=True)`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    652\u001b[0m     )\n\u001b[0;32m    654\u001b[0m routed_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_method_params(method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m, props\u001b[38;5;241m=\u001b[39mparams)\n\u001b[1;32m--> 655\u001b[0m Xt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraw_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    656\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_message(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)):\n\u001b[0;32m    657\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32md:\\new_stock_prediction\\venv\\lib\\site-packages\\sklearn\\pipeline.py:589\u001b[0m, in \u001b[0;36mPipeline._fit\u001b[1;34m(self, X, y, routed_params, raw_params)\u001b[0m\n\u001b[0;32m    582\u001b[0m \u001b[38;5;66;03m# Fit or load from cache the current transformer\u001b[39;00m\n\u001b[0;32m    583\u001b[0m step_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_metadata_for_step(\n\u001b[0;32m    584\u001b[0m     step_idx\u001b[38;5;241m=\u001b[39mstep_idx,\n\u001b[0;32m    585\u001b[0m     step_params\u001b[38;5;241m=\u001b[39mrouted_params[name],\n\u001b[0;32m    586\u001b[0m     all_params\u001b[38;5;241m=\u001b[39mraw_params,\n\u001b[0;32m    587\u001b[0m )\n\u001b[1;32m--> 589\u001b[0m X, fitted_transformer \u001b[38;5;241m=\u001b[39m \u001b[43mfit_transform_one_cached\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    590\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcloned_transformer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    591\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    592\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    593\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    594\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessage_clsname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPipeline\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    595\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_log_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_idx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    596\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstep_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    597\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    598\u001b[0m \u001b[38;5;66;03m# Replace the transformer of the step with the fitted\u001b[39;00m\n\u001b[0;32m    599\u001b[0m \u001b[38;5;66;03m# transformer. This is necessary when loading the transformer\u001b[39;00m\n\u001b[0;32m    600\u001b[0m \u001b[38;5;66;03m# from the cache.\u001b[39;00m\n\u001b[0;32m    601\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[step_idx] \u001b[38;5;241m=\u001b[39m (name, fitted_transformer)\n",
      "File \u001b[1;32md:\\new_stock_prediction\\venv\\lib\\site-packages\\joblib\\memory.py:326\u001b[0m, in \u001b[0;36mNotMemorizedFunc.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\new_stock_prediction\\venv\\lib\\site-packages\\sklearn\\pipeline.py:1540\u001b[0m, in \u001b[0;36m_fit_transform_one\u001b[1;34m(transformer, X, y, weight, message_clsname, message, params)\u001b[0m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[0;32m   1539\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(transformer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_transform\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1540\u001b[0m         res \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mfit_transform(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_transform\u001b[39m\u001b[38;5;124m\"\u001b[39m, {}))\n\u001b[0;32m   1541\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1542\u001b[0m         res \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m, {}))\u001b[38;5;241m.\u001b[39mtransform(\n\u001b[0;32m   1543\u001b[0m             X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransform\u001b[39m\u001b[38;5;124m\"\u001b[39m, {})\n\u001b[0;32m   1544\u001b[0m         )\n",
      "File \u001b[1;32md:\\new_stock_prediction\\venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py:316\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    315\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 316\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    317\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    318\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    319\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    320\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    321\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    322\u001b[0m         )\n",
      "File \u001b[1;32md:\\new_stock_prediction\\venv\\lib\\site-packages\\sklearn\\base.py:1365\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1358\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1360\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1361\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1362\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1363\u001b[0m     )\n\u001b[0;32m   1364\u001b[0m ):\n\u001b[1;32m-> 1365\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\new_stock_prediction\\venv\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:988\u001b[0m, in \u001b[0;36mColumnTransformer.fit_transform\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    985\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_transformers()\n\u001b[0;32m    986\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(X)\n\u001b[1;32m--> 988\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_column_callables\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    989\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_remainder(X)\n\u001b[0;32m    991\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _routing_enabled():\n",
      "File \u001b[1;32md:\\new_stock_prediction\\venv\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:541\u001b[0m, in \u001b[0;36mColumnTransformer._validate_column_callables\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    539\u001b[0m         columns \u001b[38;5;241m=\u001b[39m columns(X)\n\u001b[0;32m    540\u001b[0m     all_columns\u001b[38;5;241m.\u001b[39mappend(columns)\n\u001b[1;32m--> 541\u001b[0m     transformer_to_input_indices[name] \u001b[38;5;241m=\u001b[39m \u001b[43m_get_column_indices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    543\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_columns \u001b[38;5;241m=\u001b[39m all_columns\n\u001b[0;32m    544\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transformer_to_input_indices \u001b[38;5;241m=\u001b[39m transformer_to_input_indices\n",
      "File \u001b[1;32md:\\new_stock_prediction\\venv\\lib\\site-packages\\sklearn\\utils\\_indexing.py:445\u001b[0m, in \u001b[0;36m_get_column_indices\u001b[1;34m(X, key)\u001b[0m\n\u001b[0;32m    443\u001b[0m         col_idx \u001b[38;5;241m=\u001b[39m all_columns\u001b[38;5;241m.\u001b[39mget_loc(col)\n\u001b[0;32m    444\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(col_idx, numbers\u001b[38;5;241m.\u001b[39mIntegral):\n\u001b[1;32m--> 445\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    446\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSelected columns, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcolumns\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, are not unique in dataframe\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    447\u001b[0m             )\n\u001b[0;32m    448\u001b[0m         column_indices\u001b[38;5;241m.\u001b[39mappend(col_idx)\n\u001b[0;32m    450\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mValueError\u001b[0m: Selected columns, ['Open', 'High', 'Low', 'Close'], are not unique in dataframe"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# 4. Evaluate with TimeSeriesSplit\n",
    "# -------------------------------\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    mae_scores, r2_scores = [], []\n",
    "    pipeline = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"model\", model)])\n",
    "    \n",
    "    for train_idx, test_idx in tscv.split(X):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "        \n",
    "        pipeline.fit(X_train, y_train)\n",
    "        y_pred = pipeline.predict(X_test)\n",
    "        \n",
    "        mae_scores.append(mean_absolute_error(y_test, y_pred))\n",
    "        r2_scores.append(r2_score(y_test, y_pred))\n",
    "    \n",
    "    results[name] = {\"MAE\": np.mean(mae_scores), \"R²\": np.mean(r2_scores)}\n",
    "\n",
    "results_df = pd.DataFrame(results).T.sort_values(by=\"MAE\")\n",
    "print(\"\\nModel Performance (Cross-Validation):\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821aa17f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\INDIA\\AppData\\Local\\Temp\\ipykernel_86424\\238843100.py:25: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  df = yf.download(ticker, start=start, end=end)\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Performance (Cross-Validation):\n",
      "                        MAE        R²\n",
      "Linear Regression  2.391450  0.921143\n",
      "Stacking           2.976327  0.888551\n",
      "Voting             6.702505  0.269279\n",
      "Weighted Voting    7.672900 -0.001707\n",
      "Random Forest      9.109742 -0.493245\n",
      "Gradient Boosting  9.232680 -0.502380\n",
      "\n",
      "✅ Best Model Selected: Linear Regression\n",
      "\n",
      "📈 Predicted next close price for AAPL (tomorrow): 232.66\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestRegressor,\n",
    "    GradientBoostingRegressor,\n",
    "    VotingRegressor,\n",
    "    StackingRegressor\n",
    ")\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "import yfinance as yf\n",
    "from datetime import datetime\n",
    "\n",
    "# -------------------------------\n",
    "# 1. Download Stock Data (AAPL)\n",
    "# -------------------------------\n",
    "ticker = \"AAPL\"\n",
    "start = \"2022-01-01\"\n",
    "end = datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "df = yf.download(ticker, start=start, end=end)\n",
    "\n",
    "# Flatten multi-index (sometimes yfinance returns multi-level headers)\n",
    "df.columns = df.columns.get_level_values(0)\n",
    "\n",
    "# Keep OHLC only\n",
    "df = df.loc[:, [\"Open\", \"High\", \"Low\", \"Close\"]].reset_index()\n",
    "\n",
    "# Create target: Next day's Close\n",
    "df[\"Next_Close\"] = df[\"Close\"].shift(-1)\n",
    "df = df.dropna().reset_index(drop=True)\n",
    "\n",
    "# -------------------------------\n",
    "# 2. Features & Preprocessor\n",
    "# -------------------------------\n",
    "features = [\"Open\", \"High\", \"Low\", \"Close\"]\n",
    "X = df[features]\n",
    "y = df[\"Next_Close\"]\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[(\"num\", StandardScaler(), features)],\n",
    "    remainder=\"passthrough\"\n",
    ")\n",
    "\n",
    "# -------------------------------\n",
    "# 3. Candidate Models\n",
    "# -------------------------------\n",
    "lr = LinearRegression()\n",
    "rf = RandomForestRegressor(n_estimators=200, max_depth=10, random_state=42)\n",
    "gb = GradientBoostingRegressor(n_estimators=200, learning_rate=0.05, max_depth=5, random_state=42)\n",
    "\n",
    "voting_reg = VotingRegressor(estimators=[(\"lr\", lr), (\"rf\", rf), (\"gb\", gb)])\n",
    "weighted_voting_reg = VotingRegressor(\n",
    "    estimators=[(\"lr\", lr), (\"rf\", rf), (\"gb\", gb)],\n",
    "    weights=[1, 2, 2]\n",
    ")\n",
    "stacking_reg = StackingRegressor(\n",
    "    estimators=[(\"lr\", lr), (\"rf\", rf), (\"gb\", gb)],\n",
    "    final_estimator=Ridge(alpha=1.0)\n",
    ")\n",
    "\n",
    "models = {\n",
    "    \"Linear Regression\": lr,\n",
    "    \"Random Forest\": rf,\n",
    "    \"Gradient Boosting\": gb,\n",
    "    \"Voting\": voting_reg,\n",
    "    \"Weighted Voting\": weighted_voting_reg,\n",
    "    \"Stacking\": stacking_reg\n",
    "}\n",
    "\n",
    "# -------------------------------\n",
    "# 4. Evaluate with TimeSeriesSplit\n",
    "# -------------------------------\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    mae_scores, r2_scores = [], []\n",
    "    pipeline = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"model\", model)])\n",
    "    \n",
    "    for train_idx, test_idx in tscv.split(X):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "        \n",
    "        pipeline.fit(X_train, y_train)\n",
    "        y_pred = pipeline.predict(X_test)\n",
    "        \n",
    "        mae_scores.append(mean_absolute_error(y_test, y_pred))\n",
    "        r2_scores.append(r2_score(y_test, y_pred))\n",
    "    \n",
    "    results[name] = {\"MAE\": np.mean(mae_scores), \"R²\": np.mean(r2_scores)}\n",
    "\n",
    "results_df = pd.DataFrame(results).T.sort_values(by=\"MAE\")\n",
    "print(\"\\nModel Performance (Cross-Validation):\")\n",
    "print(results_df)\n",
    "\n",
    "# -------------------------------\n",
    "# 5. AutoML: Pick Best Model\n",
    "# -------------------------------\n",
    "best_model_name = results_df.index[0]\n",
    "print(f\"\\n✅ Best Model Selected: {best_model_name}\")\n",
    "\n",
    "best_model = models[best_model_name]\n",
    "final_pipeline = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"model\", best_model)])\n",
    "\n",
    "# Train best model on all data\n",
    "final_pipeline.fit(X, y)\n",
    "\n",
    "# -------------------------------\n",
    "# 6. Predict Tomorrow’s Price\n",
    "# -------------------------------\n",
    "latest_features = df[features].iloc[-1:]\n",
    "next_day_prediction = final_pipeline.predict(latest_features)[0]\n",
    "\n",
    "print(f\"\\n📈 Predicted next close price for {ticker} (tomorrow): {next_day_prediction:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14468619",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
