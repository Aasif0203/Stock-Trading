{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa1f9802",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\INDIA\\AppData\\Local\\Temp\\ipykernel_83752\\3032045284.py:25: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  df = yf.download(ticker, start=start, end=end)\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Performance (Cross-Validation):\n",
      "                         MAE        RÂ²\n",
      "Linear Regression   4.306243  0.920628\n",
      "Stacking            4.346578  0.916928\n",
      "Voting             14.095907  0.292117\n",
      "Weighted Voting    16.322630  0.027392\n",
      "Gradient Boosting  19.656044 -0.473217\n",
      "Random Forest      19.779291 -0.445991\n",
      "\n",
      "âœ… Best Model Selected: Linear Regression\n",
      "\n",
      "ðŸ“ˆ Predicted next close price for MSFT (tomorrow): 522.70\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestRegressor,\n",
    "    GradientBoostingRegressor,\n",
    "    VotingRegressor,\n",
    "    StackingRegressor\n",
    ")\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "import yfinance as yf\n",
    "from datetime import datetime\n",
    "\n",
    "# -------------------------------\n",
    "# 1. Download Stock Data (AAPL)\n",
    "# -------------------------------\n",
    "ticker = \"MSFT\"\n",
    "start = \"2022-01-01\"\n",
    "end = datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "df = yf.download(ticker, start=start, end=end)\n",
    "\n",
    "# Flatten multi-index (sometimes yfinance returns multi-level headers)\n",
    "df.columns = df.columns.get_level_values(0)\n",
    "\n",
    "# Keep OHLC only\n",
    "df = df.loc[:, [\"Open\", \"High\", \"Low\", \"Close\"]].reset_index()\n",
    "\n",
    "# Create target: Next day's Close\n",
    "df[\"Next_Close\"] = df[\"Close\"].shift(-1)\n",
    "df = df.dropna().reset_index(drop=True)\n",
    "\n",
    "# -------------------------------\n",
    "# 2. Features & Preprocessor\n",
    "# -------------------------------\n",
    "features = [\"Open\", \"High\", \"Low\", \"Close\"]\n",
    "X = df[features]\n",
    "y = df[\"Next_Close\"]\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[(\"num\", StandardScaler(), features)],\n",
    "    remainder=\"passthrough\"\n",
    ")\n",
    "\n",
    "# -------------------------------\n",
    "# 3. Candidate Models\n",
    "# -------------------------------\n",
    "lr = LinearRegression()\n",
    "rf = RandomForestRegressor(n_estimators=200, max_depth=10, random_state=42)\n",
    "gb = GradientBoostingRegressor(n_estimators=200, learning_rate=0.05, max_depth=5, random_state=42)\n",
    "\n",
    "voting_reg = VotingRegressor(estimators=[(\"lr\", lr), (\"rf\", rf), (\"gb\", gb)])\n",
    "weighted_voting_reg = VotingRegressor(\n",
    "    estimators=[(\"lr\", lr), (\"rf\", rf), (\"gb\", gb)],\n",
    "    weights=[1, 2, 2]\n",
    ")\n",
    "stacking_reg = StackingRegressor(\n",
    "    estimators=[(\"lr\", lr), (\"rf\", rf), (\"gb\", gb)],\n",
    "    final_estimator=Ridge(alpha=1.0)\n",
    ")\n",
    "\n",
    "models = {\n",
    "    \"Linear Regression\": lr,\n",
    "    \"Random Forest\": rf,\n",
    "    \"Gradient Boosting\": gb,\n",
    "    \"Voting\": voting_reg,\n",
    "    \"Weighted Voting\": weighted_voting_reg,\n",
    "    \"Stacking\": stacking_reg\n",
    "}\n",
    "\n",
    "# -------------------------------\n",
    "# 4. Evaluate with TimeSeriesSplit\n",
    "# -------------------------------\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    mae_scores, r2_scores = [], []\n",
    "    pipeline = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"model\", model)])\n",
    "    \n",
    "    for train_idx, test_idx in tscv.split(X):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "        \n",
    "        pipeline.fit(X_train, y_train)\n",
    "        y_pred = pipeline.predict(X_test)\n",
    "        \n",
    "        mae_scores.append(mean_absolute_error(y_test, y_pred))\n",
    "        r2_scores.append(r2_score(y_test, y_pred))\n",
    "    \n",
    "    results[name] = {\"MAE\": np.mean(mae_scores), \"RÂ²\": np.mean(r2_scores)}\n",
    "\n",
    "results_df = pd.DataFrame(results).T.sort_values(by=\"MAE\")\n",
    "print(\"\\nModel Performance (Cross-Validation):\")\n",
    "print(results_df)\n",
    "\n",
    "# -------------------------------\n",
    "# 5. AutoML: Pick Best Model\n",
    "# -------------------------------\n",
    "best_model_name = results_df.index[0]\n",
    "print(f\"\\nâœ… Best Model Selected: {best_model_name}\")\n",
    "\n",
    "best_model = models[best_model_name]\n",
    "final_pipeline = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"model\", best_model)])\n",
    "\n",
    "# Train best model on all data\n",
    "final_pipeline.fit(X, y)\n",
    "\n",
    "# -------------------------------\n",
    "# 6. Predict Tomorrowâ€™s Price\n",
    "# -------------------------------\n",
    "latest_features = df[features].iloc[-1:]\n",
    "next_day_prediction = final_pipeline.predict(latest_features)[0]\n",
    "\n",
    "print(f\"\\nðŸ“ˆ Predicted next close price for {ticker} (tomorrow): {next_day_prediction:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3d0e3c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\INDIA\\AppData\\Local\\Temp\\ipykernel_83752\\3985275913.py:26: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  df = yf.download(ticker, start=start, end=end)\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Performance (Cross-Validation):\n",
      "                         MAE        RÂ²\n",
      "Linear Regression   3.987967  0.976207\n",
      "Lasso Regression    3.989701  0.976206\n",
      "Ridge Regression    4.029964  0.975940\n",
      "Stacking            4.949561  0.960995\n",
      "Voting             17.697104  0.362180\n",
      "Weighted Voting    20.661459  0.100348\n",
      "Random Forest      25.021764 -0.369900\n",
      "Gradient Boosting  25.278918 -0.390415\n",
      "\n",
      "âœ… Best ML Model Selected: Linear Regression\n",
      "ðŸ’¾ Model saved as MSFT_20250817.joblib\n",
      "\n",
      "ðŸ“ˆ Predicted next close (ML AutoML) for MSFT (tomorrow): 522.85\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestRegressor,\n",
    "    GradientBoostingRegressor,\n",
    "    VotingRegressor,\n",
    "    StackingRegressor\n",
    ")\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "import yfinance as yf\n",
    "from datetime import datetime\n",
    "\n",
    "# -------------------------------\n",
    "# 1. Download Stock Data (e.g., GOOG)\n",
    "# -------------------------------\n",
    "ticker = \"MSFT\"\n",
    "start = \"2020-01-01\"\n",
    "end = datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "df = yf.download(ticker, start=start, end=end)\n",
    "\n",
    "# Flatten possible MultiIndex columns\n",
    "df.columns = df.columns.get_level_values(0)\n",
    "\n",
    "# Keep OHLC\n",
    "df = df.loc[:, [\"Open\", \"High\", \"Low\", \"Close\"]].reset_index()\n",
    "\n",
    "# Create target: Next day's Close\n",
    "df[\"Next_Close\"] = df[\"Close\"].shift(-1)\n",
    "df = df.dropna().reset_index(drop=True)\n",
    "\n",
    "# -------------------------------\n",
    "# 2. Features & Preprocessor\n",
    "# -------------------------------\n",
    "features = [\"Open\", \"High\", \"Low\", \"Close\"]\n",
    "X = df[features]\n",
    "y = df[\"Next_Close\"]\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[(\"num\", StandardScaler(), features)],\n",
    "    remainder=\"drop\"\n",
    ")\n",
    "\n",
    "# -------------------------------\n",
    "# 3. Candidate ML Models\n",
    "# -------------------------------\n",
    "lr = LinearRegression()\n",
    "ridge = Ridge(alpha=1.0)\n",
    "lasso = Lasso(alpha=0.001, max_iter=30000)\n",
    "rf = RandomForestRegressor(n_estimators=200, max_depth=10, random_state=42)\n",
    "gb = GradientBoostingRegressor(n_estimators=200, learning_rate=0.05, max_depth=5, random_state=42)\n",
    "\n",
    "voting_reg = VotingRegressor(estimators=[(\"lr\", lr), (\"rf\", rf), (\"gb\", gb)])\n",
    "weighted_voting_reg = VotingRegressor(\n",
    "    estimators=[(\"lr\", lr), (\"rf\", rf), (\"gb\", gb)],\n",
    "    weights=[1, 2, 2]\n",
    ")\n",
    "stacking_reg = StackingRegressor(\n",
    "    estimators=[(\"lr\", lr), (\"rf\", rf), (\"gb\", gb)],\n",
    "    final_estimator=Ridge(alpha=1.0)\n",
    ")\n",
    "\n",
    "models = {\n",
    "    \"Linear Regression\": lr,\n",
    "    \"Ridge Regression\": ridge,\n",
    "    \"Lasso Regression\": lasso,\n",
    "    \"Random Forest\": rf,\n",
    "    \"Gradient Boosting\": gb,\n",
    "    \"Voting\": voting_reg,\n",
    "    \"Weighted Voting\": weighted_voting_reg,\n",
    "    \"Stacking\": stacking_reg\n",
    "}\n",
    "\n",
    "# -------------------------------\n",
    "# 4. Evaluate ML Models\n",
    "# -------------------------------\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    mae_scores, r2_scores = [], []\n",
    "    pipeline = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"model\", model)])\n",
    "    \n",
    "    for train_idx, test_idx in tscv.split(X):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "        \n",
    "        pipeline.fit(X_train, y_train)\n",
    "        y_pred = pipeline.predict(X_test)\n",
    "        \n",
    "        mae_scores.append(mean_absolute_error(y_test, y_pred))\n",
    "        r2_scores.append(r2_score(y_test, y_pred))\n",
    "    \n",
    "    results[name] = {\"MAE\": np.mean(mae_scores), \"RÂ²\": np.mean(r2_scores)}\n",
    "\n",
    "# -------------------------------\n",
    "# 5. Results\n",
    "# -------------------------------\n",
    "results_df = pd.DataFrame(results).T.sort_values(by=\"MAE\", na_position=\"last\")\n",
    "print(\"\\nModel Performance (Cross-Validation):\")\n",
    "print(results_df)\n",
    "\n",
    "# -------------------------------\n",
    "# 6. AutoML: Pick Best ML Model\n",
    "# -------------------------------\n",
    "best_model_name = results_df.dropna().index[0]\n",
    "print(f\"\\nâœ… Best ML Model Selected: {best_model_name}\")\n",
    "\n",
    "best_model = models[best_model_name]\n",
    "final_pipeline = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"model\", best_model)])\n",
    "final_pipeline.fit(X, y)\n",
    "\n",
    "# -------------------------------\n",
    "# 7. Save Model as {ticker}_{today}.joblib\n",
    "# -------------------------------\n",
    "today_str = datetime.today().strftime(\"%Y%m%d\")\n",
    "model_filename = f\"{ticker}_{today_str}.joblib\"\n",
    "joblib.dump(final_pipeline, model_filename)\n",
    "print(f\"ðŸ’¾ Model saved as {model_filename}\")\n",
    "\n",
    "# -------------------------------\n",
    "# 8. Predict Tomorrowâ€™s Price\n",
    "# -------------------------------\n",
    "latest_features = df[features].iloc[-1:]\n",
    "next_day_prediction = final_pipeline.predict(latest_features)[0]\n",
    "\n",
    "print(f\"\\nðŸ“ˆ Predicted next close (ML AutoML) for {ticker} (tomorrow): {next_day_prediction:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eecee661",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
