{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "433962cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\new_stock_prediction\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "d:\\new_stock_prediction\\venv\\lib\\site-packages\\sklearn\\utils\\deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "d:\\new_stock_prediction\\venv\\lib\\site-packages\\sklearn\\utils\\deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "d:\\new_stock_prediction\\venv\\lib\\site-packages\\sklearn\\utils\\deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "d:\\new_stock_prediction\\venv\\lib\\site-packages\\sklearn\\utils\\deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "d:\\new_stock_prediction\\venv\\lib\\site-packages\\sklearn\\utils\\deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "d:\\new_stock_prediction\\venv\\lib\\site-packages\\sklearn\\utils\\deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "d:\\new_stock_prediction\\venv\\lib\\site-packages\\sklearn\\utils\\deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "d:\\new_stock_prediction\\venv\\lib\\site-packages\\sklearn\\utils\\deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "d:\\new_stock_prediction\\venv\\lib\\site-packages\\sklearn\\utils\\deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "d:\\new_stock_prediction\\venv\\lib\\site-packages\\sklearn\\utils\\deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "d:\\new_stock_prediction\\venv\\lib\\site-packages\\sklearn\\utils\\deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "d:\\new_stock_prediction\\venv\\lib\\site-packages\\sklearn\\utils\\deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "d:\\new_stock_prediction\\venv\\lib\\site-packages\\sklearn\\utils\\deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "d:\\new_stock_prediction\\venv\\lib\\site-packages\\sklearn\\utils\\deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "d:\\new_stock_prediction\\venv\\lib\\site-packages\\sklearn\\utils\\deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "d:\\new_stock_prediction\\venv\\lib\\site-packages\\sklearn\\utils\\deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "d:\\new_stock_prediction\\venv\\lib\\site-packages\\sklearn\\utils\\deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "d:\\new_stock_prediction\\venv\\lib\\site-packages\\sklearn\\utils\\deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "d:\\new_stock_prediction\\venv\\lib\\site-packages\\sklearn\\utils\\deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARIMA failed: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:25:04 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:25:05 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Performance (Cross-Validation):\n",
      "                         MAE        RÂ²\n",
      "Linear Regression   1.554560  0.981721\n",
      "Lasso Regression    1.562035  0.981659\n",
      "Ridge Regression    1.595152  0.981252\n",
      "Stacking            1.734317  0.972200\n",
      "Voting             11.746111  0.116262\n",
      "Weighted Voting    13.961998 -0.262640\n",
      "Gradient Boosting  17.274948 -0.951409\n",
      "Random Forest      17.328091 -0.968408\n",
      "Prophet                  NaN       NaN\n",
      "\n",
      "âœ… Best ML Model Selected: Linear Regression\n",
      "\n",
      "ðŸ“ˆ Predicted next close (ML AutoML) for AAPL (tomorrow): 232.76\n",
      "ðŸ”® Prophet Forecast (returns â†’ price): 233.21\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestRegressor,\n",
    "    GradientBoostingRegressor,\n",
    "    VotingRegressor,\n",
    "    StackingRegressor\n",
    ")\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "import yfinance as yf\n",
    "from datetime import datetime\n",
    "from pmdarima import auto_arima\n",
    "from prophet import Prophet\n",
    "\n",
    "# -------------------------------\n",
    "# 1. Download Stock Data (AAPL)\n",
    "# -------------------------------\n",
    "ticker = \"AAPL\"\n",
    "start = \"2015-01-01\"   # use longer history for Prophet\n",
    "end = datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "df = yf.download(ticker, start=start, end=end, auto_adjust=False)\n",
    "df.columns = df.columns.get_level_values(0)\n",
    "\n",
    "# Keep OHLC\n",
    "df = df.loc[:, [\"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]].reset_index()\n",
    "\n",
    "# Create daily returns\n",
    "df[\"Return\"] = df[\"Close\"].pct_change()\n",
    "df[\"Next_Return\"] = df[\"Return\"].shift(-1)\n",
    "df[\"Next_Close\"] = df[\"Close\"].shift(-1)\n",
    "df = df.dropna().reset_index(drop=True)\n",
    "\n",
    "# -------------------------------\n",
    "# 2. Features & Preprocessor (ML)\n",
    "# -------------------------------\n",
    "features = [\"Open\", \"High\", \"Low\", \"Close\"]\n",
    "X = df[features]\n",
    "y = df[\"Next_Close\"]\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[(\"num\", StandardScaler(), features)],\n",
    "    remainder=\"passthrough\"\n",
    ")\n",
    "\n",
    "# -------------------------------\n",
    "# 3. Candidate ML Models\n",
    "# -------------------------------\n",
    "lr = LinearRegression()\n",
    "ridge = Ridge(alpha=1.0)\n",
    "lasso = Lasso(alpha=0.001, max_iter=10000)\n",
    "rf = RandomForestRegressor(n_estimators=200, max_depth=10, random_state=42)\n",
    "gb = GradientBoostingRegressor(n_estimators=200, learning_rate=0.05, max_depth=5, random_state=42)\n",
    "\n",
    "voting_reg = VotingRegressor(estimators=[(\"lr\", lr), (\"rf\", rf), (\"gb\", gb)])\n",
    "weighted_voting_reg = VotingRegressor(\n",
    "    estimators=[(\"lr\", lr), (\"rf\", rf), (\"gb\", gb)],\n",
    "    weights=[1, 2, 2]\n",
    ")\n",
    "stacking_reg = StackingRegressor(\n",
    "    estimators=[(\"lr\", lr), (\"rf\", rf), (\"gb\", gb)],\n",
    "    final_estimator=Ridge(alpha=1.0)\n",
    ")\n",
    "\n",
    "models = {\n",
    "    \"Linear Regression\": lr,\n",
    "    \"Ridge Regression\": ridge,\n",
    "    \"Lasso Regression\": lasso,\n",
    "    \"Random Forest\": rf,\n",
    "    \"Gradient Boosting\": gb,\n",
    "    \"Voting\": voting_reg,\n",
    "    \"Weighted Voting\": weighted_voting_reg,\n",
    "    \"Stacking\": stacking_reg\n",
    "}\n",
    "\n",
    "# -------------------------------\n",
    "# 4. Evaluate ML Models\n",
    "# -------------------------------\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    mae_scores, r2_scores = [], []\n",
    "    pipeline = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"model\", model)])\n",
    "    \n",
    "    for train_idx, test_idx in tscv.split(X):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "        \n",
    "        pipeline.fit(X_train, y_train)\n",
    "        y_pred = pipeline.predict(X_test)\n",
    "        \n",
    "        mae_scores.append(mean_absolute_error(y_test, y_pred))\n",
    "        r2_scores.append(r2_score(y_test, y_pred))\n",
    "    \n",
    "    results[name] = {\"MAE\": np.mean(mae_scores), \"RÂ²\": np.mean(r2_scores)}\n",
    "\n",
    "# -------------------------------\n",
    "# 5. Auto ARIMA (on Returns)\n",
    "# -------------------------------\n",
    "try:\n",
    "    arima_model = auto_arima(df[\"Return\"].dropna(), seasonal=False, trace=False, suppress_warnings=True)\n",
    "    arima_forecast = arima_model.predict(n_periods=1)[0]\n",
    "    # Convert predicted return back to price\n",
    "    arima_predicted_close = df[\"Close\"].iloc[-1] * (1 + arima_forecast)\n",
    "    results[\"ARIMA\"] = {\"MAE\": np.nan, \"RÂ²\": np.nan}\n",
    "except Exception as e:\n",
    "    print(\"ARIMA failed:\", e)\n",
    "    arima_predicted_close = None\n",
    "\n",
    "# -------------------------------\n",
    "# 6. Prophet (on Returns)\n",
    "# -------------------------------\n",
    "try:\n",
    "    prophet_df = df[[\"Date\", \"Return\"]].rename(columns={\"Date\": \"ds\", \"Return\": \"y\"}).dropna()\n",
    "    prophet = Prophet(daily_seasonality=True)\n",
    "    prophet.fit(prophet_df)\n",
    "    future = prophet.make_future_dataframe(periods=1)\n",
    "    forecast = prophet.predict(future)\n",
    "    prophet_forecast_return = forecast.iloc[-1][\"yhat\"]\n",
    "    prophet_predicted_close = df[\"Close\"].iloc[-1] * (1 + prophet_forecast_return)\n",
    "    results[\"Prophet\"] = {\"MAE\": np.nan, \"RÂ²\": np.nan}\n",
    "except Exception as e:\n",
    "    print(\"Prophet failed:\", e)\n",
    "    prophet_predicted_close = None\n",
    "\n",
    "# -------------------------------\n",
    "# 7. Results\n",
    "# -------------------------------\n",
    "results_df = pd.DataFrame(results).T.sort_values(by=\"MAE\", na_position=\"last\")\n",
    "print(\"\\nModel Performance (Cross-Validation):\")\n",
    "print(results_df)\n",
    "\n",
    "# -------------------------------\n",
    "# 8. AutoML: Pick Best ML Model\n",
    "# -------------------------------\n",
    "best_model_name = results_df.dropna().index[0]\n",
    "print(f\"\\nâœ… Best ML Model Selected: {best_model_name}\")\n",
    "\n",
    "best_model = models[best_model_name]\n",
    "final_pipeline = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"model\", best_model)])\n",
    "final_pipeline.fit(X, y)\n",
    "\n",
    "# -------------------------------\n",
    "# 9. Predict Tomorrowâ€™s Price\n",
    "# -------------------------------\n",
    "latest_features = df[features].iloc[-1:]\n",
    "ml_predicted_close = final_pipeline.predict(latest_features)[0]\n",
    "\n",
    "print(f\"\\nðŸ“ˆ Predicted next close (ML AutoML) for {ticker} (tomorrow): {ml_predicted_close:.2f}\")\n",
    "\n",
    "if arima_predicted_close is not None:\n",
    "    print(f\"ðŸ“‰ ARIMA Forecast (returns â†’ price): {arima_predicted_close:.2f}\")\n",
    "\n",
    "if prophet_predicted_close is not None:\n",
    "    print(f\"ðŸ”® Prophet Forecast (returns â†’ price): {prophet_predicted_close:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Performance (Cross-Validation):\n",
      "                         MAE        RÂ²\n",
      "Lasso Regression    0.770945  0.989001\n",
      "Ridge Regression    0.772363  0.988832\n",
      "Linear Regression   0.772694  0.988899\n",
      "Stacking            0.868337  0.969772\n",
      "Voting             10.629615 -0.051710\n",
      "Random Forest      15.834915 -1.345361\n",
      "Gradient Boosting  15.903886 -1.368800\n",
      "\n",
      "âœ… Best Model Selected: Lasso Regression\n",
      "\n",
      "ðŸ“ˆ Predicted next close (ML AutoML) for NVDA (tomorrow): 182.19\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestRegressor,\n",
    "    GradientBoostingRegressor,\n",
    "    VotingRegressor,\n",
    "    StackingRegressor\n",
    ")\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "import yfinance as yf\n",
    "from datetime import datetime\n",
    "\n",
    "# -------------------------------\n",
    "# 1. Download Stock Data (AAPL)\n",
    "# -------------------------------\n",
    "ticker = \"NVDA\"\n",
    "start = \"2015-01-01\"\n",
    "end = datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "df = yf.download(ticker, start=start, end=end, auto_adjust=False)\n",
    "df.columns = df.columns.get_level_values(0)\n",
    "\n",
    "# Keep OHLC\n",
    "df = df.loc[:, [\"Open\", \"High\", \"Low\", \"Close\"]].reset_index()\n",
    "\n",
    "# Create target: Next day's Close\n",
    "df[\"Next_Close\"] = df[\"Close\"].shift(-1)\n",
    "df = df.dropna().reset_index(drop=True)\n",
    "\n",
    "# -------------------------------\n",
    "# 2. Features & Preprocessor\n",
    "# -------------------------------\n",
    "features = [\"Open\", \"High\", \"Low\", \"Close\"]\n",
    "X = df[features]\n",
    "y = df[\"Next_Close\"]\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[(\"num\", StandardScaler(), features)],\n",
    "    remainder=\"passthrough\"\n",
    ")\n",
    "\n",
    "# -------------------------------\n",
    "# 3. Candidate ML Models\n",
    "# -------------------------------\n",
    "lr = LinearRegression()\n",
    "ridge = Ridge(alpha=1.0)\n",
    "lasso = Lasso(alpha=0.001, max_iter=10000)\n",
    "rf = RandomForestRegressor(n_estimators=200, max_depth=10, random_state=42)\n",
    "gb = GradientBoostingRegressor(n_estimators=200, learning_rate=0.05, max_depth=5, random_state=42)\n",
    "\n",
    "voting_reg = VotingRegressor(estimators=[(\"lr\", lr), (\"rf\", rf), (\"gb\", gb)])\n",
    "stacking_reg = StackingRegressor(\n",
    "    estimators=[(\"lr\", lr), (\"rf\", rf), (\"gb\", gb)],\n",
    "    final_estimator=Ridge(alpha=1.0)\n",
    ")\n",
    "\n",
    "models = {\n",
    "    \"Linear Regression\": lr,\n",
    "    \"Ridge Regression\": ridge,\n",
    "    \"Lasso Regression\": lasso,\n",
    "    \"Random Forest\": rf,\n",
    "    \"Gradient Boosting\": gb,\n",
    "    \"Voting\": voting_reg,\n",
    "    \"Stacking\": stacking_reg\n",
    "}\n",
    "\n",
    "# -------------------------------\n",
    "# 4. Evaluate Models\n",
    "# -------------------------------\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    mae_scores, r2_scores = [], []\n",
    "    pipeline = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"model\", model)])\n",
    "    \n",
    "    for train_idx, test_idx in tscv.split(X):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "        \n",
    "        pipeline.fit(X_train, y_train)\n",
    "        y_pred = pipeline.predict(X_test)\n",
    "        \n",
    "        mae_scores.append(mean_absolute_error(y_test, y_pred))\n",
    "        r2_scores.append(r2_score(y_test, y_pred))\n",
    "    \n",
    "    results[name] = {\"MAE\": np.mean(mae_scores), \"RÂ²\": np.mean(r2_scores)}\n",
    "\n",
    "results_df = pd.DataFrame(results).T.sort_values(by=\"MAE\")\n",
    "print(\"\\nModel Performance (Cross-Validation):\")\n",
    "print(results_df)\n",
    "\n",
    "# -------------------------------\n",
    "# 5. AutoML: Pick Best Model\n",
    "# -------------------------------\n",
    "best_model_name = results_df.index[0]\n",
    "print(f\"\\nâœ… Best Model Selected: {best_model_name}\")\n",
    "\n",
    "best_model = models[best_model_name]\n",
    "final_pipeline = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"model\", best_model)])\n",
    "final_pipeline.fit(X, y)\n",
    "\n",
    "# -------------------------------\n",
    "# 6. Predict Tomorrowâ€™s Price\n",
    "# -------------------------------\n",
    "latest_features = df[features].iloc[-1:]\n",
    "ml_predicted_close = final_pipeline.predict(latest_features)[0]\n",
    "\n",
    "print(f\"\\nðŸ“ˆ Predicted next close (ML AutoML) for {ticker} (tomorrow): {ml_predicted_close:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fd491dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "d:\\new_stock_prediction\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.777e+03, tolerance: 2.711e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\new_stock_prediction\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.430e+03, tolerance: 3.913e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š Predictions for Tech Stocks:\n",
      "  Prediction Date Ticker         Best Model  Predicted Close\n",
      "0      2025-08-15   AAPL  Linear Regression           232.76\n",
      "1      2025-08-15   MSFT           Stacking           523.06\n",
      "2      2025-08-15   AMZN  Linear Regression           231.32\n",
      "3      2025-08-15  GOOGL  Linear Regression           202.95\n",
      "4      2025-08-15   TSLA   Lasso Regression           335.44\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'openpyxl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 143\u001b[0m\n\u001b[0;32m    140\u001b[0m     predictions_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([old_df, predictions_df], ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    142\u001b[0m predictions_df\u001b[38;5;241m.\u001b[39mto_csv(csv_file, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m--> 143\u001b[0m \u001b[43mpredictions_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexcel_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mâœ… Predictions saved to \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcsv_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexcel_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\new_stock_prediction\\venv\\lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    332\u001b[0m     )\n\u001b[1;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\new_stock_prediction\\venv\\lib\\site-packages\\pandas\\core\\generic.py:2436\u001b[0m, in \u001b[0;36mNDFrame.to_excel\u001b[1;34m(self, excel_writer, sheet_name, na_rep, float_format, columns, header, index, index_label, startrow, startcol, engine, merge_cells, inf_rep, freeze_panes, storage_options, engine_kwargs)\u001b[0m\n\u001b[0;32m   2423\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mformats\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexcel\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ExcelFormatter\n\u001b[0;32m   2425\u001b[0m formatter \u001b[38;5;241m=\u001b[39m ExcelFormatter(\n\u001b[0;32m   2426\u001b[0m     df,\n\u001b[0;32m   2427\u001b[0m     na_rep\u001b[38;5;241m=\u001b[39mna_rep,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2434\u001b[0m     inf_rep\u001b[38;5;241m=\u001b[39minf_rep,\n\u001b[0;32m   2435\u001b[0m )\n\u001b[1;32m-> 2436\u001b[0m \u001b[43mformatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2437\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexcel_writer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2438\u001b[0m \u001b[43m    \u001b[49m\u001b[43msheet_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msheet_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2439\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstartrow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstartrow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2440\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstartcol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstartcol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2441\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfreeze_panes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfreeze_panes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2442\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2443\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2444\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2445\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\new_stock_prediction\\venv\\lib\\site-packages\\pandas\\io\\formats\\excel.py:943\u001b[0m, in \u001b[0;36mExcelFormatter.write\u001b[1;34m(self, writer, sheet_name, startrow, startcol, freeze_panes, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[0;32m    941\u001b[0m     need_save \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    942\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 943\u001b[0m     writer \u001b[38;5;241m=\u001b[39m \u001b[43mExcelWriter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    946\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    947\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    948\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    949\u001b[0m     need_save \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    951\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32md:\\new_stock_prediction\\venv\\lib\\site-packages\\pandas\\io\\excel\\_openpyxl.py:57\u001b[0m, in \u001b[0;36mOpenpyxlWriter.__init__\u001b[1;34m(self, path, engine, date_format, datetime_format, mode, storage_options, if_sheet_exists, engine_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m     46\u001b[0m     path: FilePath \u001b[38;5;241m|\u001b[39m WriteExcelBuffer \u001b[38;5;241m|\u001b[39m ExcelWriter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     55\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;66;03m# Use the openpyxl module as the Excel writer.\u001b[39;00m\n\u001b[1;32m---> 57\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mopenpyxl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mworkbook\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Workbook\n\u001b[0;32m     59\u001b[0m     engine_kwargs \u001b[38;5;241m=\u001b[39m combine_kwargs(engine_kwargs, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m     62\u001b[0m         path,\n\u001b[0;32m     63\u001b[0m         mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     66\u001b[0m         engine_kwargs\u001b[38;5;241m=\u001b[39mengine_kwargs,\n\u001b[0;32m     67\u001b[0m     )\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'openpyxl'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestRegressor,\n",
    "    GradientBoostingRegressor,\n",
    "    VotingRegressor,\n",
    "    StackingRegressor\n",
    ")\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "import yfinance as yf\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "\n",
    "# -------------------------------\n",
    "# 1. Candidate ML Models\n",
    "# -------------------------------\n",
    "lr = LinearRegression()\n",
    "ridge = Ridge(alpha=1.0)\n",
    "lasso = Lasso(alpha=0.001, max_iter=10000)\n",
    "rf = RandomForestRegressor(n_estimators=200, max_depth=10, random_state=42)\n",
    "gb = GradientBoostingRegressor(n_estimators=200, learning_rate=0.05, max_depth=5, random_state=42)\n",
    "\n",
    "voting_reg = VotingRegressor(estimators=[(\"lr\", lr), (\"rf\", rf), (\"gb\", gb)])\n",
    "stacking_reg = StackingRegressor(\n",
    "    estimators=[(\"lr\", lr), (\"rf\", rf), (\"gb\", gb)],\n",
    "    final_estimator=Ridge(alpha=1.0)\n",
    ")\n",
    "\n",
    "models = {\n",
    "    \"Linear Regression\": lr,\n",
    "    \"Ridge Regression\": ridge,\n",
    "    \"Lasso Regression\": lasso,\n",
    "    \"Random Forest\": rf,\n",
    "    \"Gradient Boosting\": gb,\n",
    "    \"Voting\": voting_reg,\n",
    "    \"Stacking\": stacking_reg\n",
    "}\n",
    "\n",
    "# -------------------------------\n",
    "# 2. Function to Train & Predict\n",
    "# -------------------------------\n",
    "def predict_stock(ticker, start=\"2015-01-01\"):\n",
    "    end = datetime.today().strftime('%Y-%m-%d')\n",
    "    \n",
    "    # Download stock data\n",
    "    df = yf.download(ticker, start=start, end=end, auto_adjust=False)\n",
    "    df.columns = df.columns.get_level_values(0)\n",
    "    \n",
    "    # Keep OHLC\n",
    "    df = df.loc[:, [\"Open\", \"High\", \"Low\", \"Close\"]].reset_index()\n",
    "    \n",
    "    # Create target: Next day's Close\n",
    "    df[\"Next_Close\"] = df[\"Close\"].shift(-1)\n",
    "    df = df.dropna().reset_index(drop=True)\n",
    "    \n",
    "    features = [\"Open\", \"High\", \"Low\", \"Close\"]\n",
    "    X = df[features]\n",
    "    y = df[\"Next_Close\"]\n",
    "    \n",
    "    # Preprocessor\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[(\"num\", StandardScaler(), features)],\n",
    "        remainder=\"passthrough\"\n",
    "    )\n",
    "    \n",
    "    # Evaluate Models with TimeSeriesSplit\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "    results = {}\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        mae_scores, r2_scores = [], []\n",
    "        pipeline = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"model\", model)])\n",
    "        \n",
    "        for train_idx, test_idx in tscv.split(X):\n",
    "            X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "            y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "            \n",
    "            pipeline.fit(X_train, y_train)\n",
    "            y_pred = pipeline.predict(X_test)\n",
    "            \n",
    "            mae_scores.append(mean_absolute_error(y_test, y_pred))\n",
    "            r2_scores.append(r2_score(y_test, y_pred))\n",
    "        \n",
    "        results[name] = {\"MAE\": np.mean(mae_scores), \"RÂ²\": np.mean(r2_scores)}\n",
    "    \n",
    "    results_df = pd.DataFrame(results).T.sort_values(by=\"MAE\")\n",
    "    best_model_name = results_df.index[0]\n",
    "    best_model = models[best_model_name]\n",
    "    \n",
    "    # Final Train on All Data\n",
    "    final_pipeline = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"model\", best_model)])\n",
    "    final_pipeline.fit(X, y)\n",
    "    \n",
    "    # Predict Tomorrow\n",
    "    latest_features = df[features].iloc[-1:]\n",
    "    predicted_close = final_pipeline.predict(latest_features)[0]\n",
    "    \n",
    "    # Tomorrowâ€™s actual date\n",
    "    next_date = (df[\"Date\"].iloc[-1] + timedelta(days=1)).strftime(\"%Y-%m-%d\")\n",
    "    \n",
    "    return {\n",
    "        \"ticker\": ticker,\n",
    "        \"best_model\": best_model_name,\n",
    "        \"predicted_close\": predicted_close,\n",
    "        \"prediction_date\": next_date\n",
    "    }\n",
    "\n",
    "# -------------------------------\n",
    "# 3. Run for Multiple Tech Stocks\n",
    "# -------------------------------\n",
    "tech_tickers = [\"AAPL\", \"MSFT\", \"AMZN\", \"GOOGL\", \"TSLA\"]\n",
    "\n",
    "all_predictions = []\n",
    "for t in tech_tickers:\n",
    "    output = predict_stock(t)\n",
    "    all_predictions.append({\n",
    "        \"Prediction Date\": output[\"prediction_date\"],\n",
    "        \"Ticker\": output[\"ticker\"],\n",
    "        \"Best Model\": output[\"best_model\"],\n",
    "        \"Predicted Close\": round(output[\"predicted_close\"], 2)\n",
    "    })\n",
    "\n",
    "predictions_df = pd.DataFrame(all_predictions)\n",
    "print(\"\\nðŸ“Š Predictions for Tech Stocks:\")\n",
    "print(predictions_df)\n",
    "\n",
    "# -------------------------------\n",
    "# 4. Save to CSV/Excel (Append Daily)\n",
    "# -------------------------------\n",
    "csv_file = \"tech_stock_predictions.csv\"\n",
    "excel_file = \"tech_stock_predictions.xlsx\"\n",
    "\n",
    "if os.path.exists(csv_file):\n",
    "    old_df = pd.read_csv(csv_file)\n",
    "    predictions_df = pd.concat([old_df, predictions_df], ignore_index=True)\n",
    "\n",
    "predictions_df.to_csv(csv_file, index=False)\n",
    "predictions_df.to_excel(excel_file, index=False)\n",
    "\n",
    "print(f\"\\nâœ… Predictions saved to '{csv_file}' and '{excel_file}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d4202d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\INDIA\\AppData\\Local\\Temp\\ipykernel_140052\\3260472895.py:26: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  df = yf.download(ticker, start=start, end=end)\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Performance (Cross-Validation):\n",
      "                         MAE        RÂ²\n",
      "Lasso Regression    1.350765  0.981343\n",
      "Linear Regression   1.351984  0.981239\n",
      "Ridge Regression    1.360759  0.980714\n",
      "Stacking            1.453536  0.969377\n",
      "Voting              7.837694  0.499541\n",
      "Weighted Voting     9.286432  0.289522\n",
      "Random Forest      11.365554 -0.082063\n",
      "Gradient Boosting  11.583588 -0.111793\n",
      "\n",
      "âœ… Best ML Model Selected: Lasso Regression\n",
      "ðŸ’¾ Model saved as NVDA_20250817.joblib\n",
      "\n",
      "ðŸ“ˆ Predicted next close (ML AutoML) for NVDA (tomorrow): 182.27\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestRegressor,\n",
    "    GradientBoostingRegressor,\n",
    "    VotingRegressor,\n",
    "    StackingRegressor\n",
    ")\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "import yfinance as yf\n",
    "from datetime import datetime\n",
    "\n",
    "# -------------------------------\n",
    "# 1. Download Stock Data (e.g., GOOG)\n",
    "# -------------------------------\n",
    "ticker = \"NVDA\"\n",
    "start = \"2020-01-01\"\n",
    "end = datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "df = yf.download(ticker, start=start, end=end)\n",
    "\n",
    "# Flatten possible MultiIndex columns\n",
    "df.columns = df.columns.get_level_values(0)\n",
    "\n",
    "# Keep OHLC\n",
    "df = df.loc[:, [\"Open\", \"High\", \"Low\", \"Close\"]].reset_index()\n",
    "\n",
    "# Create target: Next day's Close\n",
    "df[\"Next_Close\"] = df[\"Close\"].shift(-1)\n",
    "df = df.dropna().reset_index(drop=True)\n",
    "\n",
    "# -------------------------------\n",
    "# 2. Features & Preprocessor\n",
    "# -------------------------------\n",
    "features = [\"Open\", \"High\", \"Low\", \"Close\"]\n",
    "X = df[features]\n",
    "y = df[\"Next_Close\"]\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[(\"num\", StandardScaler(), features)],\n",
    "    remainder=\"drop\"\n",
    ")\n",
    "\n",
    "# -------------------------------\n",
    "# 3. Candidate ML Models\n",
    "# -------------------------------\n",
    "lr = LinearRegression()\n",
    "ridge = Ridge(alpha=1.0)\n",
    "lasso = Lasso(alpha=0.001, max_iter=30000)\n",
    "rf = RandomForestRegressor(n_estimators=200, max_depth=10, random_state=42)\n",
    "gb = GradientBoostingRegressor(n_estimators=200, learning_rate=0.05, max_depth=5, random_state=42)\n",
    "\n",
    "voting_reg = VotingRegressor(estimators=[(\"lr\", lr), (\"rf\", rf), (\"gb\", gb)])\n",
    "weighted_voting_reg = VotingRegressor(\n",
    "    estimators=[(\"lr\", lr), (\"rf\", rf), (\"gb\", gb)],\n",
    "    weights=[1, 2, 2]\n",
    ")\n",
    "stacking_reg = StackingRegressor(\n",
    "    estimators=[(\"lr\", lr), (\"rf\", rf), (\"gb\", gb)],\n",
    "    final_estimator=Ridge(alpha=1.0)\n",
    ")\n",
    "\n",
    "models = {\n",
    "    \"Linear Regression\": lr,\n",
    "    \"Ridge Regression\": ridge,\n",
    "    \"Lasso Regression\": lasso,\n",
    "    \"Random Forest\": rf,\n",
    "    \"Gradient Boosting\": gb,\n",
    "    \"Voting\": voting_reg,\n",
    "    \"Weighted Voting\": weighted_voting_reg,\n",
    "    \"Stacking\": stacking_reg\n",
    "}\n",
    "\n",
    "# -------------------------------\n",
    "# 4. Evaluate ML Models\n",
    "# -------------------------------\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    mae_scores, r2_scores = [], []\n",
    "    pipeline = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"model\", model)])\n",
    "    \n",
    "    for train_idx, test_idx in tscv.split(X):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "        \n",
    "        pipeline.fit(X_train, y_train)\n",
    "        y_pred = pipeline.predict(X_test)\n",
    "        \n",
    "        mae_scores.append(mean_absolute_error(y_test, y_pred))\n",
    "        r2_scores.append(r2_score(y_test, y_pred))\n",
    "    \n",
    "    results[name] = {\"MAE\": np.mean(mae_scores), \"RÂ²\": np.mean(r2_scores)}\n",
    "\n",
    "# -------------------------------\n",
    "# 5. Results\n",
    "# -------------------------------\n",
    "results_df = pd.DataFrame(results).T.sort_values(by=\"MAE\", na_position=\"last\")\n",
    "print(\"\\nModel Performance (Cross-Validation):\")\n",
    "print(results_df)\n",
    "\n",
    "# -------------------------------\n",
    "# 6. AutoML: Pick Best ML Model\n",
    "# -------------------------------\n",
    "best_model_name = results_df.dropna().index[0]\n",
    "print(f\"\\nâœ… Best ML Model Selected: {best_model_name}\")\n",
    "\n",
    "best_model = models[best_model_name]\n",
    "final_pipeline = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"model\", best_model)])\n",
    "final_pipeline.fit(X, y)\n",
    "\n",
    "# -------------------------------\n",
    "# 7. Save Model as {ticker}_{today}.joblib\n",
    "# -------------------------------\n",
    "today_str = datetime.today().strftime(\"%Y%m%d\")\n",
    "model_filename = f\"{ticker}_{today_str}.joblib\"\n",
    "joblib.dump(final_pipeline, model_filename)\n",
    "print(f\"ðŸ’¾ Model saved as {model_filename}\")\n",
    "\n",
    "# -------------------------------\n",
    "# 8. Predict Tomorrowâ€™s Price\n",
    "# -------------------------------\n",
    "latest_features = df[features].iloc[-1:]\n",
    "next_day_prediction = final_pipeline.predict(latest_features)[0]\n",
    "\n",
    "print(f\"\\nðŸ“ˆ Predicted next close (ML AutoML) for {ticker} (tomorrow): {next_day_prediction:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b04efb6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
