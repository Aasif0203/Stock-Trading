{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33d30adb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading GOOG hourly data from 2025-05-24 to 2025-08-22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\INDIA\\AppData\\Local\\Temp\\ipykernel_72412\\2756981503.py:35: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  df = yf.download(ticker, start=start.strftime('%Y-%m-%d'),\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "C:\\Users\\INDIA\\AppData\\Local\\Temp\\ipykernel_72412\\2756981503.py:130: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  df = yf.download(ticker, start=start.strftime('%Y-%m-%d'),\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model CV performance:\n",
      "                        MAE        RÂ²\n",
      "Ridge Regression   0.737010  0.819390\n",
      "Lasso Regression   0.741123  0.820437\n",
      "Linear Regression  0.744377  0.819252\n",
      "Stacking           0.764781  0.815537\n",
      "Voting             2.161412 -0.252330\n",
      "Weighted Voting    2.500677 -0.728051\n",
      "Gradient Boosting  2.987155 -1.503761\n",
      "Random Forest      3.062516 -1.716238\n",
      "\n",
      "âœ… Best model: Ridge Regression\n",
      "ðŸ’¾ Saved model as GOOG_hour.joblib\n",
      "ðŸ“ˆ Predicted next close for GOOG: 200.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\INDIA\\AppData\\Local\\Temp\\ipykernel_72412\\2756981503.py:179: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  df = yf.download(ticker, start=start.strftime('%Y-%m-%d'),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "ðŸ“ˆ HOURLY PREDICTION FOR GOOG\n",
      "==================================================\n",
      "Current Time: 2025-08-21 19:30:00+00:00\n",
      "Next Hour:    2025-08-21 20:30:00+00:00\n",
      "Current Close: $200.62\n",
      "Predicted Close: $200.70\n",
      "Predicted Change: +0.08 (+0.04%) ðŸ“ˆ\n",
      "Model: GOOG_hour.joblib\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# GLOBAL CONFIG - Change ticker only here\n",
    "# ============================================================================\n",
    "TICKER = \"GOOG\"   # <<-- Change ticker symbol here only one time\n",
    "\n",
    "# ============================================================================\n",
    "# CELL 1: Training Function\n",
    "# ============================================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestRegressor,\n",
    "    GradientBoostingRegressor,\n",
    "    VotingRegressor,\n",
    "    StackingRegressor\n",
    ")\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "import yfinance as yf\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def train_hourly_model(ticker=TICKER, days_back=90):\n",
    "    \"\"\"Train an hourly prediction model for a given ticker.\"\"\"\n",
    "    \n",
    "    # 1. Download hourly stock data\n",
    "    end = datetime.today()\n",
    "    start = end - timedelta(days=days_back)\n",
    "    print(f\"Downloading {ticker} hourly data from {start:%Y-%m-%d} to {end:%Y-%m-%d}\")\n",
    "    \n",
    "    df = yf.download(ticker, start=start.strftime('%Y-%m-%d'),\n",
    "                     end=end.strftime('%Y-%m-%d'), interval=\"60m\")\n",
    "\n",
    "    if isinstance(df.columns, pd.MultiIndex):\n",
    "        df.columns = df.columns.get_level_values(0)\n",
    "    df = df.reset_index()\n",
    "\n",
    "    required_cols = [\"Datetime\", \"Open\", \"High\", \"Low\", \"Close\"]\n",
    "    missing_cols = [col for col in required_cols if col not in df.columns]\n",
    "    if missing_cols:\n",
    "        raise ValueError(f\"Required columns {missing_cols} not found in data\")\n",
    "\n",
    "    df = df[required_cols]\n",
    "    df[\"Next_Close\"] = df[\"Close\"].shift(-1)\n",
    "    df = df.dropna().reset_index(drop=True)\n",
    "\n",
    "    features = [\"Open\", \"High\", \"Low\", \"Close\"]\n",
    "    X = df[features]\n",
    "    y = df[\"Next_Close\"]\n",
    "\n",
    "    preprocessor = ColumnTransformer([(\"num\", StandardScaler(), features)], remainder=\"drop\")\n",
    "\n",
    "    # Models\n",
    "    lr    = LinearRegression()\n",
    "    ridge = Ridge(alpha=1.0)\n",
    "    lasso = Lasso(alpha=0.001, max_iter=30000)\n",
    "    rf    = RandomForestRegressor(n_estimators=200, max_depth=10, random_state=42)\n",
    "    gb    = GradientBoostingRegressor(n_estimators=200, learning_rate=0.05, max_depth=5, random_state=42)\n",
    "    voting_reg = VotingRegressor([(\"lr\", lr), (\"rf\", rf), (\"gb\", gb)])\n",
    "    weighted_voting_reg = VotingRegressor([(\"lr\", lr), (\"rf\", rf), (\"gb\", gb)], weights=[1,2,2])\n",
    "    stacking_reg = StackingRegressor([(\"lr\", lr), (\"rf\", rf), (\"gb\", gb)], final_estimator=Ridge(alpha=1.0))\n",
    "\n",
    "    models = {\n",
    "        \"Linear Regression\": lr,\n",
    "        \"Ridge Regression\": ridge,\n",
    "        \"Lasso Regression\": lasso,\n",
    "        \"Random Forest\": rf,\n",
    "        \"Gradient Boosting\": gb,\n",
    "        \"Voting\": voting_reg,\n",
    "        \"Weighted Voting\": weighted_voting_reg,\n",
    "        \"Stacking\": stacking_reg\n",
    "    }\n",
    "\n",
    "    # Time series CV\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "    results = {}\n",
    "    for name, model in models.items():\n",
    "        mae_scores, r2_scores = [], []\n",
    "        pipeline = Pipeline([(\"scale\", preprocessor), (\"model\", model)])\n",
    "        for train_idx, test_idx in tscv.split(X):\n",
    "            X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "            y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "            pipeline.fit(X_train, y_train)\n",
    "            y_pred = pipeline.predict(X_test)\n",
    "            mae_scores.append(mean_absolute_error(y_test, y_pred))\n",
    "            r2_scores.append(r2_score(y_test, y_pred))\n",
    "        results[name] = {\"MAE\": np.mean(mae_scores), \"RÂ²\": np.mean(r2_scores)}\n",
    "\n",
    "    results_df = pd.DataFrame(results).T.sort_values(by=\"MAE\")\n",
    "    print(\"\\nModel CV performance:\")\n",
    "    print(results_df)\n",
    "\n",
    "    best_model_name = results_df.index[0]\n",
    "    print(f\"\\nâœ… Best model: {best_model_name}\")\n",
    "    best_model = models[best_model_name]\n",
    "    final_pipeline = Pipeline([(\"scale\", preprocessor), (\"model\", best_model)])\n",
    "    final_pipeline.fit(X, y)\n",
    "\n",
    "    model_filename = f\"{ticker}_hour.joblib\"\n",
    "    joblib.dump(final_pipeline, model_filename)\n",
    "    print(f\"ðŸ’¾ Saved model as {model_filename}\")\n",
    "\n",
    "    pred_next_hour = final_pipeline.predict(df[features].iloc[-1:])[0]\n",
    "    print(f\"ðŸ“ˆ Predicted next close for {ticker}: {pred_next_hour:.2f}\")\n",
    "    \n",
    "    return model_filename, best_model_name, pred_next_hour\n",
    "\n",
    "# Train model (uses global TICKER)\n",
    "model_file, best_model, prediction = train_hourly_model(days_back=90)\n",
    "\n",
    "# ============================================================================\n",
    "# CELL 2: Prediction Function\n",
    "# ============================================================================\n",
    "def predict_next_hour(ticker=TICKER, model_filename=None):\n",
    "    \"\"\"Predict the next hour's closing price using a saved model.\"\"\"\n",
    "    if model_filename is None:\n",
    "        model_filename = f\"{ticker}_hour.joblib\"\n",
    "    try:\n",
    "        pipeline = joblib.load(model_filename)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"âŒ Model file {model_filename} not found. Train the model first.\")\n",
    "        return None\n",
    "    \n",
    "    end = datetime.today()\n",
    "    start = end - timedelta(days=7)\n",
    "    df = yf.download(ticker, start=start.strftime('%Y-%m-%d'),\n",
    "                     end=end.strftime('%Y-%m-%d'), interval=\"60m\")\n",
    "    if isinstance(df.columns, pd.MultiIndex):\n",
    "        df.columns = df.columns.get_level_values(0)\n",
    "    df = df.reset_index()\n",
    "    df = df[[\"Datetime\", \"Open\", \"High\", \"Low\", \"Close\"]]\n",
    "\n",
    "    latest_data = df.iloc[-1]\n",
    "    prediction = pipeline.predict(df[[\"Open\", \"High\", \"Low\", \"Close\"]].iloc[-1:])[0]\n",
    "    next_hour = latest_data[\"Datetime\"] + timedelta(hours=1)\n",
    "    \n",
    "    return {\n",
    "        \"ticker\": ticker,\n",
    "        \"current_datetime\": latest_data[\"Datetime\"],\n",
    "        \"next_hour_datetime\": next_hour,\n",
    "        \"current_close\": latest_data[\"Close\"],\n",
    "        \"predicted_next_close\": prediction,\n",
    "        \"predicted_change\": prediction - latest_data[\"Close\"],\n",
    "        \"predicted_change_percent\": ((prediction - latest_data[\"Close\"]) / latest_data[\"Close\"]) * 100,\n",
    "        \"model_file\": model_filename\n",
    "    }\n",
    "\n",
    "def print_prediction_results(results):\n",
    "    if results is None: return\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(f\"ðŸ“ˆ HOURLY PREDICTION FOR {results['ticker']}\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Current Time: {results['current_datetime']}\")\n",
    "    print(f\"Next Hour:    {results['next_hour_datetime']}\")\n",
    "    print(f\"Current Close: ${results['current_close']:.2f}\")\n",
    "    print(f\"Predicted Close: ${results['predicted_next_close']:.2f}\")\n",
    "    change, change_pct = results['predicted_change'], results['predicted_change_percent']\n",
    "    arrow = \"ðŸ“ˆ\" if change > 0 else \"ðŸ“‰\"\n",
    "    print(f\"Predicted Change: {change:+.2f} ({change_pct:+.2f}%) {arrow}\")\n",
    "    print(f\"Model: {results['model_file']}\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "results = predict_next_hour()\n",
    "print_prediction_results(results)\n",
    "\n",
    "# ============================================================================\n",
    "# CELL 3: Visualization\n",
    "# ============================================================================\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "def plot_hourly_predictions(ticker=TICKER, days_back=7):\n",
    "    end = datetime.today()\n",
    "    start = end - timedelta(days=days_back)\n",
    "    df = yf.download(ticker, start=start.strftime('%Y-%m-%d'),\n",
    "                     end=end.strftime('%Y-%m-%d'), interval=\"60m\")\n",
    "    if isinstance(df.columns, pd.MultiIndex):\n",
    "        df.columns = df.columns.get_level_values(0)\n",
    "    df = df.reset_index()\n",
    "    \n",
    "    fig = make_subplots(rows=2, cols=1, \n",
    "                        subplot_titles=(f'{ticker} Hourly OHLC', 'Volume'),\n",
    "                        vertical_spacing=0.1)\n",
    "    fig.add_trace(go.Candlestick(x=df['Datetime'],\n",
    "                                  open=df['Open'], high=df['High'],\n",
    "                                  low=df['Low'], close=df['Close'],\n",
    "                                  name='OHLC'), row=1, col=1)\n",
    "    if 'Volume' in df.columns:\n",
    "        fig.add_trace(go.Bar(x=df['Datetime'], y=df['Volume'], name='Volume'), row=2, col=1)\n",
    "    fig.update_layout(title=f'{ticker} Hourly Data (Last {days_back} Days)', height=600)\n",
    "    \n",
    "    # âœ… Always open in browser (avoids nbformat issue)\n",
    "    fig.show(renderer=\"browser\")\n",
    "\n",
    "plot_hourly_predictions()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
