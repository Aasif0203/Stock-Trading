{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46ec50b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading ADBE hourly data from 2025-05-24 to 2025-08-22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\INDIA\\AppData\\Local\\Temp\\ipykernel_77656\\3777054838.py:42: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  df = yf.download(ticker, start=start.strftime('%Y-%m-%d'),\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (421, 6)\n",
      "Date range: 2025-05-27 13:30:00+00:00 to 2025-08-21 17:30:00+00:00\n",
      "\n",
      "Model CV performance (lower MAE is better):\n",
      "                        MAE        RÂ²\n",
      "Lasso Regression   1.735252  0.903566\n",
      "Linear Regression  1.737815  0.903337\n",
      "Ridge Regression   1.794186  0.900207\n",
      "Stacking           2.014199  0.870139\n",
      "Voting             5.096244  0.388496\n",
      "Weighted Voting    5.855703  0.177905\n",
      "Random Forest      6.869881 -0.204606\n",
      "Gradient Boosting  7.184420 -0.212128\n",
      "\n",
      "âœ… Best model: Lasso Regression\n",
      "ðŸ’¾ Saved model as ADBE_hour.joblib\n",
      "ðŸ“ˆ Predicted next close (next hour) for ADBE: 352.41\n",
      "\n",
      "Summary:\n",
      "Model file: ADBE_hour.joblib\n",
      "Best model: Lasso Regression\n",
      "Next hour prediction: $352.41\n",
      "âœ… Loaded model: ADBE_hour.joblib\n",
      "Downloading recent ADBE hourly data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\INDIA\\AppData\\Local\\Temp\\ipykernel_77656\\3777054838.py:186: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  df = yf.download(ticker, start=start.strftime('%Y-%m-%d'),\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "ðŸ“ˆ HOURLY PREDICTION FOR ADBE\n",
      "==================================================\n",
      "Current Time: 2025-08-21 18:30:00+00:00\n",
      "Next Hour:    2025-08-21 19:30:00+00:00\n",
      "Current Close: $353.19\n",
      "Predicted Close: $353.26\n",
      "Predicted Change: +$0.07 (+0.02%) ðŸ“ˆ\n",
      "Model: ADBE_hour.joblib\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\INDIA\\AppData\\Local\\Temp\\ipykernel_77656\\3777054838.py:280: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  df = yf.download(ticker, start=start.strftime('%Y-%m-%d'),\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Mime type rendering requires nbformat>=4.2.0 but it is not installed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 317\u001b[0m\n\u001b[0;32m    314\u001b[0m     fig\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m    316\u001b[0m \u001b[38;5;66;03m# Plot recent hourly data\u001b[39;00m\n\u001b[1;32m--> 317\u001b[0m \u001b[43mplot_hourly_predictions\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mADBE\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdays_back\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 314\u001b[0m, in \u001b[0;36mplot_hourly_predictions\u001b[1;34m(ticker, days_back)\u001b[0m\n\u001b[0;32m    304\u001b[0m     fig\u001b[38;5;241m.\u001b[39madd_trace(go\u001b[38;5;241m.\u001b[39mBar(x\u001b[38;5;241m=\u001b[39mdf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDatetime\u001b[39m\u001b[38;5;124m'\u001b[39m], y\u001b[38;5;241m=\u001b[39mdf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVolume\u001b[39m\u001b[38;5;124m'\u001b[39m], name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVolume\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m    305\u001b[0m                    row\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, col\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    307\u001b[0m fig\u001b[38;5;241m.\u001b[39mupdate_layout(\n\u001b[0;32m    308\u001b[0m     title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mticker\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Hourly Data (Last \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdays_back\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Days)\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    309\u001b[0m     xaxis_title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    310\u001b[0m     yaxis_title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPrice\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    311\u001b[0m     height\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m600\u001b[39m\n\u001b[0;32m    312\u001b[0m )\n\u001b[1;32m--> 314\u001b[0m \u001b[43mfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\new_stock_prediction\\venv\\lib\\site-packages\\plotly\\basedatatypes.py:3420\u001b[0m, in \u001b[0;36mBaseFigure.show\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3387\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3388\u001b[0m \u001b[38;5;124;03mShow a figure using either the default renderer(s) or the renderer(s)\u001b[39;00m\n\u001b[0;32m   3389\u001b[0m \u001b[38;5;124;03mspecified by the renderer argument\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3416\u001b[0m \u001b[38;5;124;03mNone\u001b[39;00m\n\u001b[0;32m   3417\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3418\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplotly\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpio\u001b[39;00m\n\u001b[1;32m-> 3420\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pio\u001b[38;5;241m.\u001b[39mshow(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\new_stock_prediction\\venv\\lib\\site-packages\\plotly\\io\\_renderers.py:415\u001b[0m, in \u001b[0;36mshow\u001b[1;34m(fig, renderer, validate, **kwargs)\u001b[0m\n\u001b[0;32m    410\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    411\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMime type rendering requires ipython but it is not installed\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    412\u001b[0m     )\n\u001b[0;32m    414\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m nbformat \u001b[38;5;129;01mor\u001b[39;00m Version(nbformat\u001b[38;5;241m.\u001b[39m__version__) \u001b[38;5;241m<\u001b[39m Version(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m4.2.0\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 415\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    416\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMime type rendering requires nbformat>=4.2.0 but it is not installed\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    417\u001b[0m     )\n\u001b[0;32m    419\u001b[0m display_jupyter_version_warnings()\n\u001b[0;32m    421\u001b[0m ipython_display\u001b[38;5;241m.\u001b[39mdisplay(bundle, raw\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mValueError\u001b[0m: Mime type rendering requires nbformat>=4.2.0 but it is not installed"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# FIXED CODE FOR NOTEBOOK - Copy this into your notebook cells\n",
    "# ============================================================================\n",
    "\n",
    "# CELL 1: Training Function (Copy this into your first cell)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestRegressor,\n",
    "    GradientBoostingRegressor,\n",
    "    VotingRegressor,\n",
    "    StackingRegressor\n",
    ")\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "import yfinance as yf\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def train_hourly_model(ticker=\"ADBE\", days_back=90):\n",
    "    \"\"\"\n",
    "    Train an hourly prediction model for a given ticker.\n",
    "    \n",
    "    Args:\n",
    "        ticker (str): Stock ticker symbol\n",
    "        days_back (int): Number of days to look back for training data\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (model_filename, best_model_name, prediction)\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Download hourly stock data\n",
    "    end = datetime.today()\n",
    "    start = end - timedelta(days=days_back)\n",
    "    \n",
    "    print(f\"Downloading {ticker} hourly data from {start.strftime('%Y-%m-%d')} to {end.strftime('%Y-%m-%d')}\")\n",
    "    \n",
    "    df = yf.download(ticker, start=start.strftime('%Y-%m-%d'),\n",
    "                     end=end.strftime('%Y-%m-%d'), interval=\"60m\")\n",
    "\n",
    "    # Properly handle MultiIndex columns\n",
    "    if isinstance(df.columns, pd.MultiIndex):\n",
    "        # If MultiIndex, get the first level (actual column names)\n",
    "        df.columns = df.columns.get_level_values(0)\n",
    "    \n",
    "    # Reset index to get a datetime column\n",
    "    df = df.reset_index()\n",
    "\n",
    "    # Ensure we have the required columns and they are unique\n",
    "    required_cols = [\"Datetime\", \"Open\", \"High\", \"Low\", \"Close\"]\n",
    "    available_cols = df.columns.tolist()\n",
    "\n",
    "    # Check if all required columns exist\n",
    "    missing_cols = [col for col in required_cols if col not in available_cols]\n",
    "    if missing_cols:\n",
    "        print(f\"Missing columns: {missing_cols}\")\n",
    "        print(f\"Available columns: {available_cols}\")\n",
    "        raise ValueError(f\"Required columns {missing_cols} not found in data\")\n",
    "\n",
    "    # Use only OHLC columns\n",
    "    df = df[required_cols]\n",
    "\n",
    "    # 2. Create target = next hour's Close\n",
    "    df[\"Next_Close\"] = df[\"Close\"].shift(-1)\n",
    "    df = df.dropna().reset_index(drop=True)\n",
    "\n",
    "    print(f\"Training data shape: {df.shape}\")\n",
    "    print(f\"Date range: {df['Datetime'].min()} to {df['Datetime'].max()}\")\n",
    "\n",
    "    # 3. Prepare features and target\n",
    "    features = [\"Open\", \"High\", \"Low\", \"Close\"]\n",
    "    X = df[features]\n",
    "    y = df[\"Next_Close\"]\n",
    "\n",
    "    # Standardize the numeric features\n",
    "    preprocessor = ColumnTransformer(transformers=[(\"num\", StandardScaler(), features)],\n",
    "                                     remainder=\"drop\")\n",
    "\n",
    "    # 4. Define candidate models\n",
    "    lr    = LinearRegression()\n",
    "    ridge = Ridge(alpha=1.0)\n",
    "    lasso = Lasso(alpha=0.001, max_iter=30000)\n",
    "    rf    = RandomForestRegressor(n_estimators=200, max_depth=10, random_state=42)\n",
    "    gb    = GradientBoostingRegressor(n_estimators=200, learning_rate=0.05, max_depth=5, random_state=42)\n",
    "    voting_reg = VotingRegressor(estimators=[(\"lr\", lr), (\"rf\", rf), (\"gb\", gb)])\n",
    "    weighted_voting_reg = VotingRegressor(estimators=[(\"lr\", lr), (\"rf\", rf), (\"gb\", gb)],\n",
    "                                         weights=[1,2,2])\n",
    "    stacking_reg = StackingRegressor(\n",
    "        estimators=[(\"lr\", lr), (\"rf\", rf), (\"gb\", gb)],\n",
    "        final_estimator=Ridge(alpha=1.0)\n",
    "    )\n",
    "    models = {\n",
    "        \"Linear Regression\": lr,\n",
    "        \"Ridge Regression\": ridge,\n",
    "        \"Lasso Regression\": lasso,\n",
    "        \"Random Forest\": rf,\n",
    "        \"Gradient Boosting\": gb,\n",
    "        \"Voting\": voting_reg,\n",
    "        \"Weighted Voting\": weighted_voting_reg,\n",
    "        \"Stacking\": stacking_reg\n",
    "    }\n",
    "\n",
    "    # 5. Evaluate each model with time-series CV\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "    results = {}\n",
    "    for name, model in models.items():\n",
    "        mae_scores, r2_scores = [], []\n",
    "        pipeline = Pipeline(steps=[(\"scale\", preprocessor), (\"model\", model)])\n",
    "        for train_idx, test_idx in tscv.split(X):\n",
    "            X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "            y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "            pipeline.fit(X_train, y_train)\n",
    "            y_pred = pipeline.predict(X_test)\n",
    "            mae_scores.append(mean_absolute_error(y_test, y_pred))\n",
    "            r2_scores.append(r2_score(y_test, y_pred))\n",
    "        results[name] = {\"MAE\": np.mean(mae_scores), \"RÂ²\": np.mean(r2_scores)}\n",
    "\n",
    "    results_df = pd.DataFrame(results).T.sort_values(by=\"MAE\")\n",
    "    print(\"\\nModel CV performance (lower MAE is better):\")\n",
    "    print(results_df)\n",
    "\n",
    "    # 6. Select best model and retrain on all data\n",
    "    best_model_name = results_df.index[0]\n",
    "    print(f\"\\nâœ… Best model: {best_model_name}\")\n",
    "    best_model = models[best_model_name]\n",
    "    final_pipeline = Pipeline(steps=[(\"scale\", preprocessor), (\"model\", best_model)])\n",
    "    final_pipeline.fit(X, y)\n",
    "\n",
    "    # 7. Save the trained model pipeline\n",
    "    model_filename = f\"{ticker}_hour.joblib\"\n",
    "    joblib.dump(final_pipeline, model_filename)\n",
    "    print(f\"ðŸ’¾ Saved model as {model_filename}\")\n",
    "\n",
    "    # 8. Predict next hour's closing price\n",
    "    latest_features = df[features].iloc[-1:].copy()\n",
    "    pred_next_hour = final_pipeline.predict(latest_features)[0]\n",
    "    print(f\"ðŸ“ˆ Predicted next close (next hour) for {ticker}: {pred_next_hour:.2f}\")\n",
    "    \n",
    "    return model_filename, best_model_name, pred_next_hour\n",
    "\n",
    "# Train model for AAPL\n",
    "model_file, best_model, prediction = train_hourly_model(\"ADBE\", days_back=90)\n",
    "print(f\"\\nSummary:\")\n",
    "print(f\"Model file: {model_file}\")\n",
    "print(f\"Best model: {best_model}\")\n",
    "print(f\"Next hour prediction: ${prediction:.2f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# CELL 2: Prediction Function (Copy this into your second cell)\n",
    "# ============================================================================\n",
    "\n",
    "def predict_next_hour(ticker, model_filename=None):\n",
    "    \"\"\"\n",
    "    Predict the next hour's closing price using a saved model.\n",
    "    \n",
    "    Args:\n",
    "        ticker (str): Stock ticker symbol\n",
    "        model_filename (str): Path to the saved model file. If None, uses default naming.\n",
    "    \n",
    "    Returns:\n",
    "        dict: Prediction results\n",
    "    \"\"\"\n",
    "    \n",
    "    # Use default model filename if not provided\n",
    "    if model_filename is None:\n",
    "        model_filename = f\"{ticker}_hour.joblib\"\n",
    "    \n",
    "    try:\n",
    "        # Load the trained model\n",
    "        pipeline = joblib.load(model_filename)\n",
    "        print(f\"âœ… Loaded model: {model_filename}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"âŒ Model file {model_filename} not found. Please train the model first.\")\n",
    "        return None\n",
    "    \n",
    "    # Download recent hourly data for prediction\n",
    "    end = datetime.today()\n",
    "    start = end - timedelta(days=7)  # Get last 7 days of hourly data\n",
    "    \n",
    "    print(f\"Downloading recent {ticker} hourly data...\")\n",
    "    \n",
    "    df = yf.download(ticker, start=start.strftime('%Y-%m-%d'),\n",
    "                     end=end.strftime('%Y-%m-%d'), interval=\"60m\")\n",
    "    \n",
    "    # Handle MultiIndex columns\n",
    "    if isinstance(df.columns, pd.MultiIndex):\n",
    "        df.columns = df.columns.get_level_values(0)\n",
    "    \n",
    "    df = df.reset_index()\n",
    "    \n",
    "    # Ensure we have required columns\n",
    "    required_cols = [\"Datetime\", \"Open\", \"High\", \"Low\", \"Close\"]\n",
    "    available_cols = df.columns.tolist()\n",
    "    \n",
    "    missing_cols = [col for col in required_cols if col not in available_cols]\n",
    "    if missing_cols:\n",
    "        print(f\"âŒ Missing columns: {missing_cols}\")\n",
    "        return None\n",
    "    \n",
    "    # Use only OHLC columns\n",
    "    df = df[required_cols]\n",
    "    \n",
    "    # Get the latest data point for prediction\n",
    "    latest_data = df.iloc[-1]\n",
    "    latest_features = df[[\"Open\", \"High\", \"Low\", \"Close\"]].iloc[-1:].copy()\n",
    "    \n",
    "    # Make prediction\n",
    "    prediction = pipeline.predict(latest_features)[0]\n",
    "    \n",
    "    # Calculate next hour timestamp\n",
    "    next_hour = latest_data[\"Datetime\"] + timedelta(hours=1)\n",
    "    \n",
    "    # Prepare results\n",
    "    results = {\n",
    "        \"ticker\": ticker,\n",
    "        \"current_datetime\": latest_data[\"Datetime\"],\n",
    "        \"next_hour_datetime\": next_hour,\n",
    "        \"current_close\": latest_data[\"Close\"],\n",
    "        \"predicted_next_close\": prediction,\n",
    "        \"predicted_change\": prediction - latest_data[\"Close\"],\n",
    "        \"predicted_change_percent\": ((prediction - latest_data[\"Close\"]) / latest_data[\"Close\"]) * 100,\n",
    "        \"model_file\": model_filename\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "def print_prediction_results(results):\n",
    "    \"\"\"Pretty print the prediction results.\"\"\"\n",
    "    if results is None:\n",
    "        return\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(f\"ðŸ“ˆ HOURLY PREDICTION FOR {results['ticker']}\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Current Time: {results['current_datetime']}\")\n",
    "    print(f\"Next Hour:    {results['next_hour_datetime']}\")\n",
    "    print(f\"Current Close: ${results['current_close']:.2f}\")\n",
    "    print(f\"Predicted Close: ${results['predicted_next_close']:.2f}\")\n",
    "    \n",
    "    change = results['predicted_change']\n",
    "    change_pct = results['predicted_change_percent']\n",
    "    \n",
    "    if change > 0:\n",
    "        print(f\"Predicted Change: +${change:.2f} (+{change_pct:.2f}%) ðŸ“ˆ\")\n",
    "    else:\n",
    "        print(f\"Predicted Change: ${change:.2f} ({change_pct:.2f}%) ðŸ“‰\")\n",
    "    \n",
    "    print(f\"Model: {results['model_file']}\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "# Example usage - predict next hour for AAPL\n",
    "results = predict_next_hour(\"ADBE\")\n",
    "\n",
    "if results:\n",
    "    print_prediction_results(results)\n",
    "else:\n",
    "    print(f\"\\nTo train a model for AAPL, run the training cell above first.\")\n",
    "\n",
    "# ============================================================================\n",
    "# CELL 3: Visualization (Copy this into your third cell)\n",
    "# ============================================================================\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "def plot_hourly_predictions(ticker=\"ADBE\", days_back=7):\n",
    "    \"\"\"\n",
    "    Plot recent hourly data and predictions.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Download recent data\n",
    "    end = datetime.today()\n",
    "    start = end - timedelta(days=days_back)\n",
    "    \n",
    "    df = yf.download(ticker, start=start.strftime('%Y-%m-%d'),\n",
    "                     end=end.strftime('%Y-%m-%d'), interval=\"60m\")\n",
    "    \n",
    "    if isinstance(df.columns, pd.MultiIndex):\n",
    "        df.columns = df.columns.get_level_values(0)\n",
    "    \n",
    "    df = df.reset_index()\n",
    "    \n",
    "    # Create plot\n",
    "    fig = make_subplots(rows=2, cols=1, \n",
    "                        subplot_titles=(f'{ticker} Hourly OHLC', 'Volume'),\n",
    "                        vertical_spacing=0.1)\n",
    "    \n",
    "    # Candlestick chart\n",
    "    fig.add_trace(go.Candlestick(x=df['Datetime'],\n",
    "                                  open=df['Open'],\n",
    "                                  high=df['High'],\n",
    "                                  low=df['Low'],\n",
    "                                  close=df['Close'],\n",
    "                                  name='OHLC'),\n",
    "                   row=1, col=1)\n",
    "    \n",
    "    # Volume chart\n",
    "    if 'Volume' in df.columns:\n",
    "        fig.add_trace(go.Bar(x=df['Datetime'], y=df['Volume'], name='Volume'),\n",
    "                       row=2, col=1)\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=f'{ticker} Hourly Data (Last {days_back} Days)',\n",
    "        xaxis_title='Date',\n",
    "        yaxis_title='Price',\n",
    "        height=600\n",
    "    )\n",
    "    \n",
    "    fig.show()\n",
    "\n",
    "# Plot recent hourly data\n",
    "plot_hourly_predictions(\"ADBE\", days_back=7)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57e843a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
